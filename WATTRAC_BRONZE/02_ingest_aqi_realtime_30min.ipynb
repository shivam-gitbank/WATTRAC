{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Databricks notebook source\n",
        "# MAGIC %md\n",
        "# MAGIC # Bronze Ingestion - AQI Realtime (30 min)\n",
        "# MAGIC Pulls near-real-time AQI snapshots for Indian metro cities at 30-minute intervals.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# COMMAND ----------\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "import requests\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# COMMAND ----------\n",
        "# aqi_api_url example: https://api.waqi.info/feed\n",
        "# endpoint pattern expected: {aqi_api_url}/{city}/?token={aqi_api_token}\n",
        "\n",
        "dbutils.widgets.text(\"aqi_api_url\", \"https://api.waqi.info/feed\")\n",
        "dbutils.widgets.text(\"aqi_api_token\", \"\")\n",
        "dbutils.widgets.text(\"cities_csv\", \"delhi,mumbai,bengaluru,kolkata,chennai,hyderabad,pune,ahmedabad\")\n",
        "dbutils.widgets.text(\"bronze_catalog\", \"main\")\n",
        "dbutils.widgets.text(\"bronze_schema\", \"wattrac_bronze\")\n",
        "dbutils.widgets.text(\"aqi_table\", \"aqi_realtime_raw\")\n",
        "\n",
        "AQI_API_URL = dbutils.widgets.get(\"aqi_api_url\").rstrip(\"/\")\n",
        "AQI_API_TOKEN = dbutils.widgets.get(\"aqi_api_token\")\n",
        "CITIES = [c.strip() for c in dbutils.widgets.get(\"cities_csv\").split(\",\") if c.strip()]\n",
        "BRONZE_CATALOG = dbutils.widgets.get(\"bronze_catalog\")\n",
        "BRONZE_SCHEMA = dbutils.widgets.get(\"bronze_schema\")\n",
        "AQI_TABLE = dbutils.widgets.get(\"aqi_table\")\n",
        "TARGET_TABLE = f\"{BRONZE_CATALOG}.{BRONZE_SCHEMA}.{AQI_TABLE}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# COMMAND ----------\n",
        "def get_city_aqi(city: str):\n",
        "    url = f\"{AQI_API_URL}/{city}/\"\n",
        "    params = {\"token\": AQI_API_TOKEN}\n",
        "    for attempt in range(3):\n",
        "        resp = requests.get(url, params=params, timeout=45)\n",
        "        if resp.ok:\n",
        "            return resp.json()\n",
        "        time.sleep((attempt + 1) * 5)\n",
        "    resp.raise_for_status()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# COMMAND ----------\n",
        "schema = StructType([\n",
        "    StructField(\"city\", StringType(), False),\n",
        "    StructField(\"aqi\", DoubleType(), True),\n",
        "    StructField(\"dominant_pollutant\", StringType(), True),\n",
        "    StructField(\"station_name\", StringType(), True),\n",
        "    StructField(\"station_lat\", DoubleType(), True),\n",
        "    StructField(\"station_lon\", DoubleType(), True),\n",
        "    StructField(\"source_observation_ts\", TimestampType(), True),\n",
        "    StructField(\"ingestion_ts\", TimestampType(), False),\n",
        "    StructField(\"ingestion_date\", StringType(), False),\n",
        "    StructField(\"raw_payload\", StringType(), False),\n",
        "])\n",
        "\n",
        "run_ts = datetime.now(timezone.utc)\n",
        "rows = []\n",
        "for city in CITIES:\n",
        "    payload = get_city_aqi(city)\n",
        "    data = payload.get(\"data\", {})\n",
        "    city_info = data.get(\"city\", {})\n",
        "    geo = city_info.get(\"geo\", [None, None])\n",
        "    rows.append({\n",
        "        \"city\": city,\n",
        "        \"aqi\": float(data.get(\"aqi\")) if data.get(\"aqi\") not in (None, \"-\") else None,\n",
        "        \"dominant_pollutant\": data.get(\"dominentpol\"),\n",
        "        \"station_name\": city_info.get(\"name\"),\n",
        "        \"station_lat\": float(geo[0]) if geo and geo[0] is not None else None,\n",
        "        \"station_lon\": float(geo[1]) if len(geo) > 1 and geo[1] is not None else None,\n",
        "        \"source_observation_ts\": run_ts,\n",
        "        \"ingestion_ts\": run_ts,\n",
        "        \"ingestion_date\": run_ts.strftime(\"%Y-%m-%d\"),\n",
        "        \"raw_payload\": json.dumps(payload),\n",
        "    })\n",
        "\n",
        "bronze_df = spark.createDataFrame(rows, schema=schema)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# COMMAND ----------\n",
        "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {BRONZE_CATALOG}.{BRONZE_SCHEMA}\")\n",
        "(bronze_df.write\n",
        " .format(\"delta\")\n",
        " .mode(\"append\")\n",
        " .partitionBy(\"ingestion_date\")\n",
        " .saveAsTable(TARGET_TABLE))\n",
        "\n",
        "display(bronze_df)\n",
        "print(f\"Inserted {bronze_df.count()} rows into {TARGET_TABLE}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 5
}