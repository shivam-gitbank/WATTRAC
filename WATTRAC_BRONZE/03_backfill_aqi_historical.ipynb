{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Databricks notebook source\n",
        "# MAGIC %md\n",
        "# MAGIC # Bronze Backfill - AQI Historical (one-time or ad-hoc)\n",
        "# MAGIC Loads historical AQI for a date range to seed the Bronze layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# COMMAND ----------\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import requests\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# COMMAND ----------\n",
        "# historical API assumed pattern:\n",
        "# {aqi_history_api_url}?city={city}&start={YYYY-MM-DD}&end={YYYY-MM-DD}&token={token}\n",
        "\n",
        "dbutils.widgets.text(\"aqi_history_api_url\", \"\")\n",
        "dbutils.widgets.text(\"aqi_api_token\", \"\")\n",
        "dbutils.widgets.text(\"cities_csv\", \"delhi,mumbai,bengaluru\")\n",
        "dbutils.widgets.text(\"start_date\", \"2024-01-01\")\n",
        "dbutils.widgets.text(\"end_date\", \"2024-12-31\")\n",
        "dbutils.widgets.text(\"bronze_catalog\", \"main\")\n",
        "dbutils.widgets.text(\"bronze_schema\", \"wattrac_bronze\")\n",
        "dbutils.widgets.text(\"historical_table\", \"aqi_historical_raw\")\n",
        "\n",
        "API_URL = dbutils.widgets.get(\"aqi_history_api_url\")\n",
        "TOKEN = dbutils.widgets.get(\"aqi_api_token\")\n",
        "CITIES = [c.strip() for c in dbutils.widgets.get(\"cities_csv\").split(\",\") if c.strip()]\n",
        "START_DATE = dbutils.widgets.get(\"start_date\")\n",
        "END_DATE = dbutils.widgets.get(\"end_date\")\n",
        "BRONZE_CATALOG = dbutils.widgets.get(\"bronze_catalog\")\n",
        "BRONZE_SCHEMA = dbutils.widgets.get(\"bronze_schema\")\n",
        "TABLE_NAME = dbutils.widgets.get(\"historical_table\")\n",
        "TARGET_TABLE = f\"{BRONZE_CATALOG}.{BRONZE_SCHEMA}.{TABLE_NAME}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# COMMAND ----------\n",
        "def daterange(start: str, end: str):\n",
        "    cur = datetime.strptime(start, \"%Y-%m-%d\").date()\n",
        "    stop = datetime.strptime(end, \"%Y-%m-%d\").date()\n",
        "    while cur <= stop:\n",
        "        yield cur.isoformat()\n",
        "        cur += timedelta(days=1)\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"city\", StringType(), False),\n",
        "    StructField(\"observation_date\", StringType(), False),\n",
        "    StructField(\"avg_aqi\", DoubleType(), True),\n",
        "    StructField(\"min_aqi\", DoubleType(), True),\n",
        "    StructField(\"max_aqi\", DoubleType(), True),\n",
        "    StructField(\"pm25\", DoubleType(), True),\n",
        "    StructField(\"pm10\", DoubleType(), True),\n",
        "    StructField(\"no2\", DoubleType(), True),\n",
        "    StructField(\"so2\", DoubleType(), True),\n",
        "    StructField(\"co\", DoubleType(), True),\n",
        "    StructField(\"o3\", DoubleType(), True),\n",
        "    StructField(\"ingestion_ts\", TimestampType(), False),\n",
        "    StructField(\"ingestion_date\", StringType(), False),\n",
        "    StructField(\"raw_payload\", StringType(), False),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# COMMAND ----------\n",
        "rows = []\n",
        "run_ts = datetime.utcnow()\n",
        "\n",
        "for city in CITIES:\n",
        "    for dt in daterange(START_DATE, END_DATE):\n",
        "        params = {\"city\": city, \"start\": dt, \"end\": dt, \"token\": TOKEN}\n",
        "        response = requests.get(API_URL, params=params, timeout=60)\n",
        "        response.raise_for_status()\n",
        "        payload = response.json()\n",
        "        metrics = payload.get(\"data\", {})\n",
        "\n",
        "        rows.append({\n",
        "            \"city\": city,\n",
        "            \"observation_date\": dt,\n",
        "            \"avg_aqi\": metrics.get(\"avg_aqi\"),\n",
        "            \"min_aqi\": metrics.get(\"min_aqi\"),\n",
        "            \"max_aqi\": metrics.get(\"max_aqi\"),\n",
        "            \"pm25\": metrics.get(\"pm25\"),\n",
        "            \"pm10\": metrics.get(\"pm10\"),\n",
        "            \"no2\": metrics.get(\"no2\"),\n",
        "            \"so2\": metrics.get(\"so2\"),\n",
        "            \"co\": metrics.get(\"co\"),\n",
        "            \"o3\": metrics.get(\"o3\"),\n",
        "            \"ingestion_ts\": run_ts,\n",
        "            \"ingestion_date\": run_ts.strftime(\"%Y-%m-%d\"),\n",
        "            \"raw_payload\": json.dumps(payload),\n",
        "        })\n",
        "\n",
        "hist_df = spark.createDataFrame(rows, schema=schema)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# COMMAND ----------\n",
        "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {BRONZE_CATALOG}.{BRONZE_SCHEMA}\")\n",
        "(hist_df.write\n",
        " .format(\"delta\")\n",
        " .mode(\"append\")\n",
        " .partitionBy(\"ingestion_date\")\n",
        " .saveAsTable(TARGET_TABLE))\n",
        "\n",
        "display(hist_df)\n",
        "print(f\"Inserted {hist_df.count()} rows into {TARGET_TABLE}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 5
}